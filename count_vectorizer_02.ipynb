{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys to bunch/dictionary that fetch_20newsgroups returns:\n",
      "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR', 'description'])\n",
      "\n",
      "\n",
      "-------------- training document --------------\n",
      "From: lerxst@wam.umd.edu (where's my thing)\n",
      "Subject: WHAT car is this!?\n",
      "Nntp-Posting-Host: rac3.wam.umd.edu\n",
      "Organization: University of Maryland, College Park\n",
      "Lines: 15\n",
      "\n",
      " I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "\n",
      "Thanks,\n",
      "- IL\n",
      "   ---- brought to you by your neighborhood Lerxst ----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-------------- Assigned category --------------\n",
      "index of target: 7\n",
      "category: rec.autos\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "raw_texts = fetch_20newsgroups(subset='train', shuffle=True)\n",
    "\n",
    "print('keys to bunch/dictionary that fetch_20newsgroups returns:')\n",
    "print(raw_texts.keys())\n",
    "\n",
    "print('\\n\\n-------------- training document --------------')\n",
    "print(raw_texts.data[0])\n",
    "\n",
    "print('\\n\\n-------------- Assigned category --------------')\n",
    "target_index = raw_texts.target[0]\n",
    "print(\"index of target: {}\".format(target_index))\n",
    "print(\"category: {}\".format(raw_texts.target_names[target_index]))\n",
    "\n",
    "#vectorizer = CountVectorizer()\n",
    "\n",
    "# Let's make a matrix of word count vectors that\n",
    "# a machine learning algorithm can understand\n",
    "#X = vectorizer.fit_transform(raw_texts.data)\n",
    "\n",
    "#feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "#print(\"Below are the {} feature names:\".format(len(feature_names)))\n",
    "#print(feature_names)\n",
    "\n",
    "#print('\\n2-D array of feature vectors:')\n",
    "#print(X.toarray())  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
